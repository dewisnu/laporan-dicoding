# -*- coding: utf-8 -*-
"""Predectivie Analysy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xWCkk8kS9zwApOI9B8bbFscooUPy_x8X

#Prepare Datasets
I Gede Ari Wisnu Sanjaya
"""

!pip install kaggle

!mkdir ~/.kaggle

!touch ~/.kaggle/kaggle.json

api_token = {"username":"dewisnus","key":"248d855b392dedd2cdf8b0e64e83cfaa"}

import json

with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)

!chmod 600 ~/.kaggle/kaggle.json

!mkdir datasets

!kaggle datasets download axeltorbenson/unemployment-data-19482021

!unzip /content/unemployment-data-19482021.zip -d datasets/

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

df = pd.read_csv('/content/datasets/unemployment_rate_data.csv')
df

"""#Data Uderstanding

*  Memberikan informasi jumlah data, kondisi data , dan informasi mengenai data yang digunakan

* Menuliskan tautan sumber data (link download)
https://www.kaggle.com/datasets/axeltorbenson/unemployment-data-19482021

* Menguraikan seluruh variabel atau fitur pada data.
* Melakukan beberapa tahapan yang diperlukan untuk memahami data contohnya teknik visualisasi data atau exploratory data analysis.




<br>

### infomasi mengenai kolom:

* unrate: total jumlah pengganguran keseluruhan
* unrate_men: total jumlah pengganguran pria
* unrate_women: total jumlah pengganguran wanita
* unrate_16_to_17: total jumlah penggaguran umur 16
  sampai 17 tahun
* unrate_18_to_19: total jumlah penggaguran umur 18 sampai 19 tahun
* unrate_20_to_24: total jumlah pengganguran umur 20 sampai 24 tahun
* unrate_25_to_34: total jumlah pengganguran umur 25 sampai 34 tahun
* unrate_35_to_44: total jumlah pengganguran umur 35 sampai 44 tahun
* unrate_45_to_54:total jumlah pengganguran umur 45 sampai 54 tahun
* unrate_55_over: total jumlah penganguran umur 55 dan diatas umur 55

<br>

###Note
unrate adalah jumlah pengganguran keseluruhan yang akan kita prediksi , sisanya adalah tipe penganguran nya . Data ini sudah clean dan tidak ada null , total data/raw kisaran 887 (sudah melebihi minimum data yang di sarankan)

"""

df.shape

df.info()

df.describe()

"""#EDA"""

df['date'] = pd.to_datetime(df['date'])

df.info()

plt.title(f'Data dari tahun ke tahun')
plt.plot(df['date'], df['unrate'])
plt.show()

year = df['date'].dt.year
year

year.unique()

for y in year.unique():
  plt.title(f'Tahun {y}')
  plt.plot(df[df['date'].dt.year == y].unrate)
  plt.show()

# Cek Outliers
# Ada error ternyata harus Float sedangkan dataframe masih ada Date jadi di drop dulu
columns = np.delete(df.columns, 0)
for col in columns:
  plt.title(f'Column {col}')
  sns.boxplot(df[col])
  plt.show()

# Next Step adalah Cek Korelasi antaar Column karena Column Date gak ke pake jadi kita drop dulu
new_df = df.drop('date', axis=1)
new_df

plt.figure(figsize=(10,10))
sns.heatmap(new_df.corr(), annot=True, cmap='coolwarm',linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)
plt.show()

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(new_df, diag_kind = 'kde')

# Terlalu besar agak sulit dilihat
sns.pairplot(df[['unrate','unrate_men','unrate_women', 'unrate_16_to_17']], plot_kws={"s": 4});

# By Class of unemployment
sns.pairplot(df[['unrate_18_to_19','unrate_20_to_24','unrate_25_to_34', 'unrate_35_to_44']], plot_kws={"s": 4});

# By Class of unemployment
sns.pairplot(df[['unrate_45_to_54','unrate_55_over']], plot_kws={"s": 2});

"""#Data Preparation
* Menerapkan dan menyebutkan teknik data preparation yang dilakukan
* Teknik yang digunakan pada notebook dan laporan harus berurutan
* Menjelaskan proses data preparation yang dilakukan
* Menjelaskan alasan mengapa diperlukan tahapan data preparation tersebut.
"""

from scipy import stats
z = np.abs(stats.zscore(new_df))
print(z)

z.shape

threshold = 3
print(np.where(z > 3))

print(z['unrate'][420])

"""##Removing Outliers"""

new_df_o = new_df
new_df_o = new_df_o[(z < 3).all(axis=1)]

new_df.shape

new_df_o.shape

new_df_o1 = new_df

Q1 = new_df_o1.quantile(0.25)
Q3 = new_df_o1.quantile(0.75)
IQR = Q3 - Q1
print(IQR)

print(new_df_o1 < (Q1 - 1.5 * IQR)) or (new_df_o1 > (Q3 + 1.5 * IQR))

new_df_out = new_df_o1[~((new_df_o1 < (Q1 - 1.5 * IQR)) |(new_df_o1 > (Q3 + 1.5 * IQR))).any(axis=1)]

new_df_out.shape

sns.pairplot(new_df_out, diag_kind = 'kde')

new_df_out.head()

df.head()

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

final_df = new_df_out
scaler.fit(final_df[final_df.columns])
final_df[final_df.columns] = scaler.transform(final_df.loc[:, final_df.columns])

final_df

final_df.describe()

# Abis di Standar tinggal di split, jadi data test tinggal tembak aja pake pred
from sklearn.model_selection import train_test_split

X, y = final_df.drop('unrate', axis=1), final_df['unrate']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=767)

"""#Modelling
* Membuat model machine learning untuk menyelesaikan permasalahan
* Menjelasakan tahapan dan parameter yang digunakan pada proses permodelan
* Menjelaskan kelebihan dan kekurangan dari setiap algoritma yang digunakan
* Jika menggunakan satu algoritma pada solution statement, lakukan proses improvement terhadap model dengan hyperparameter tuning. Jelaskan proses improvement yang dilakukan.
* Jika menggunakan dua atau lebih algoritma pada solution statement, maka pilih model terbaik sebagai solusi. Jelaskan mengapa memilih model tersebut sebagai model terbaik.

<br>

**Penulis akan menggunakan lazy predict untuk membantu mencapai hasil yang terbaik dalam membuat model machine learning**

link dokumentasi lazy predict di https://lazypredict.readthedocs.io/en/latest/usage.html#regression

"""

!pip install lazypredict

from lazypredict.Supervised import LazyRegressor

# Declare the Function
reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )

models,predictions = reg.fit(x_train, x_test, y_train, y_test)

models

# Training 4 Model Teratas

from sklearn.linear_model import LassoCV
from sklearn.svm import NuSVR
from sklearn.linear_model import ElasticNetCV
from sklearn.linear_model import LassoLarsCV

from sklearn.metrics import mean_squared_error, r2_score

# Siapkan dataframe untuk analisis model
report = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['LassoCV', 'NuSVR', 'ElasticNetCV', 'LassoLarsCV'])

# buat model prediksi
# n_estimator = number of tree in the forest
# max_depth = max kedalaman tree, ini hapus aja biar unlimited
# n_jobs = -1 using all processor
lassoCV = LassoCV()
lassoCV.fit(x_train, y_train)

nsvr = NuSVR()
nsvr.fit(x_train, y_train)

elasticCV=ElasticNetCV()
elasticCV.fit(x_train, y_train)

lassoLarsCV = LassoLarsCV()
lassoLarsCV.fit(x_train, y_train)

"""#Evaluation"""

final_report = {'Model_Name': [], 'mse': [], 'r2': []}
pred = lassoCV .predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
final_report['Model_Name'].append('LassoCV')
final_report['mse'].append(mse)
final_report['r2'].append(r2)
pred = nsvr.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
final_report['Model_Name'].append('NuSVR')
final_report['mse'].append(mse)
final_report['r2'].append(r2)
pred = elasticCV.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
final_report['Model_Name'].append('ElasticNetCV')
final_report['mse'].append(mse)
final_report['r2'].append(r2)
pred = lassoLarsCV.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
final_report['Model_Name'].append('LassoLarsCV')
final_report['mse'].append(mse)
final_report['r2'].append(r2)

final_report

pd.options.display.float_format = '{:.7f}'.format

final_report = pd.DataFrame.from_dict(final_report)
final_report

final_report['rmse'] = np.sqrt(final_report['mse'])

final_report

# GB sama RF sama mse, rmse, r2 nya
model_dict = {'RF': RF, 'XGB': XGB, 'GB': GB, 'LGBM': LGBM}
prediksi = x_test.iloc[:120].copy()
pred_dict = {'y_true':y_test[:120]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)